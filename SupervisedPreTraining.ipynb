{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "aecaeaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    %run MoleculeGenerator2.ipynb\n",
    "#    %run Discrim.ipynb\n",
    " #   %run ChemEnv.ipynb\n",
    "    %run MolUtils.ipynb\n",
    "    #%run Tests.ipynb\n",
    "\n",
    "    \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import time\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "0a7cfae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataLoader():\n",
    "    def __init__(self,path,batch_size, length):\n",
    "        self.path = path\n",
    "        self.length = length\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.indicies = list(range(length))\n",
    "        random.shuffle(self.indicies)\n",
    "        \n",
    "        self.curr_idx = 0\n",
    "        \n",
    "    def __get_exs(self,indices):\n",
    "        graphs, graph_dict = dgl.load_graphs(self.path, indices)\n",
    "        last_action = torch.stack([graph_dict['last_action'][idx] for idx in indices],dim = 0)\n",
    "        last_atom_feat = torch.stack([graph_dict['last_atom_feats'][idx] for idx in indices], dim = 0)\n",
    "        action = torch.stack([graph_dict['actions'][idx] for idx in indices], dim = 0)\n",
    "        graphs = dgl.batch(graphs)\n",
    "        return graphs.to(device), torch.unsqueeze(last_action,dim=1).to(device), last_atom_feat.to(device), action.to(device)\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.curr_idx + self.batch_size > self.length:\n",
    "            self.curr_idx = 0 \n",
    "            random.shuffle(self.indicies)       \n",
    "        batch_indices = self.indicies[self.curr_idx: self.curr_idx+self.batch_size]\n",
    "        self.curr_idx += self.batch_size\n",
    "    \n",
    "        return self.__get_exs(batch_indices)\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "7c3cc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "1e198f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs, graph_dict = dgl.load_graphs('./graph_decomp/full_chunka', [i for i in range(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "751cdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = [int(i) for i in (graph_dict['actions'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "6ef58055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([6.38860e+04, 1.19678e+05, 5.09700e+04, 2.64000e+03, 3.31200e+03,\n",
       "        3.76000e+02, 2.36000e+02, 1.71000e+02, 2.60000e+01, 8.69100e+03,\n",
       "        2.15600e+03, 8.38870e+04, 0.00000e+00, 7.39310e+04, 3.01890e+04,\n",
       "        0.00000e+00, 2.02570e+04, 1.55790e+04, 1.14210e+04, 0.00000e+00,\n",
       "        7.91300e+03, 4.85900e+03, 0.00000e+00, 3.57900e+03, 2.14100e+03,\n",
       "        1.12200e+03, 0.00000e+00, 4.82000e+02, 2.50000e+01, 2.00000e+00]),\n",
       " array([ 0.        ,  1.43333333,  2.86666667,  4.3       ,  5.73333333,\n",
       "         7.16666667,  8.6       , 10.03333333, 11.46666667, 12.9       ,\n",
       "        14.33333333, 15.76666667, 17.2       , 18.63333333, 20.06666667,\n",
       "        21.5       , 22.93333333, 24.36666667, 25.8       , 27.23333333,\n",
       "        28.66666667, 30.1       , 31.53333333, 32.96666667, 34.4       ,\n",
       "        35.83333333, 37.26666667, 38.7       , 40.13333333, 41.56666667,\n",
       "        43.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(4)\n",
    "# plt.hist(l, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "df73c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedTrainingWrapper():\n",
    "    def __init__(self, input_dim, batch_size, num_atom_types, writer, data_set_size, path = './graph_decomp/full_chunka'):\n",
    "        #svt = SupervisedTrainingWrapper(54,5,15,None)\n",
    "        self.path = path        \n",
    "        self.policy = BaseLine(input_dim,300,17+1).cuda()\n",
    "        self.optim = Adam(self.policy.parameters(), lr=3e-4)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.chunk_idx = 0\n",
    "        \n",
    "        self.writer = writer\n",
    "        self.n_iter = 0\n",
    "        self.cv_iter = 0\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.data_set_size = data_set_size\n",
    "        self.dataIter = GraphDataLoader(path,batch_size,data_set_size)\n",
    "        print(data_set_size)\n",
    "\n",
    "    def CalcAccuracy(self):\n",
    "        a,b,c,d = next(self.dataIter)\n",
    "        return self.calc_accuracy(a,b,c,d)\n",
    "    \n",
    "    \n",
    "    def calc_accuracy(self,graphs, last_action_nodes, last_atom_feats, actions):\n",
    "        y_logits = self.policy(graphs, last_action_nodes, last_atom_feats)\n",
    "        values, pred_labels = y_logits.max(dim=1)\n",
    "        acc = sum(pred_labels == actions)/actions.size()[0]\n",
    "        return acc\n",
    "    \n",
    "    def calc_accuracy_no_call(self,logits,actions):\n",
    "        values, pred_labels = logits.max(dim=1)\n",
    "        acc = sum(pred_labels == actions)/actions.size()[0]\n",
    "        return acc\n",
    "        \n",
    "        \n",
    "    def Train(self,num_epochs):\n",
    "        steps_per_epoch = self.data_set_size//self.batch_size\n",
    "        \n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            acc = self.CalcAccuracy()\n",
    "            t0 = time()\n",
    "            for step in range(steps_per_epoch):\n",
    "                self._train()\n",
    "            self._train()\n",
    "            t1 = time()\n",
    "            \n",
    "            print(f'Time for epoch {i} is {t1-t0}, random accuracy is {acc}')\n",
    "            \n",
    "            \n",
    "    def _train(self,calc_accuracy = True, update = True):\n",
    "        graphs, last_action_nodes, last_atom_feats, actions = next(self.dataIter)\n",
    "        \n",
    "        pred = self.policy.forward(graphs, last_action_nodes,last_atom_feats, softmax=False)\n",
    "        loss = self.loss_fn(pred,actions.long())\n",
    "        \n",
    "        if calc_accuracy:\n",
    "            acc = self.calc_accuracy_no_call(pred,actions)\n",
    "            self.writer.add_scalar(\"Accuracy\", acc, self.n_iter)\n",
    "        \n",
    "        if update:\n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "        self.writer.add_scalar(\"pre_train_loss\", loss.detach(), self.n_iter)\n",
    "        self.n_iter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "2642fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # svt = SupervisedTrainingWrapper(54, 2, 17, None, 10000)\n",
    "# # svt.Train(2)\n",
    "# a,b,c,d = (next(svt.dataIter))\n",
    "# print(a)\n",
    "# svt.calc_accuracy(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "2b935d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gd = GraphDataLoader('./graph_decomp/full_chunka',10,500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "610e9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run MoleculeGenerator2.ipynb\n",
    "# svt = SupervisedTrainingWrapper(54, 100, 17, None, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "78dd4e07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.3903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.3120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.2341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.1536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.0680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.9756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.8750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.7653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.6455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.5151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.3732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.2194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.6793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.0163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.7684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.6531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.0315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.7096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Time for epoch 0 is 8.460585832595825\n",
      "tensor(2.2868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8899, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Time for epoch 1 is 8.23081374168396\n",
      "tensor(1.3184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2786/2715987401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2786/1992414193.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2786/1992414193.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, update)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#print(last_action_nodes.shape, last_atom_feats.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_action_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_atom_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m#print(pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2786/3985533502.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, last_action_node, last_node, softmax)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchEdge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_node\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddNode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2786/4291373412.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graphs, last_node_batch, h)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bond_pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0medges_per_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bond_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36munbatch\u001b[0;34m(g, node_split, edge_split)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;31m# Create graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     gs = [convert.heterograph(edge_dict, num_nodes_dict, idtype=g.idtype)\n\u001b[0;32m--> 401\u001b[0;31m           for edge_dict, num_nodes_dict in zip(edge_dict_per, num_nodes_dict_per)]\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;31m# Unbatch node features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;31m# Create graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     gs = [convert.heterograph(edge_dict, num_nodes_dict, idtype=g.idtype)\n\u001b[0;32m--> 401\u001b[0;31m           for edge_dict, num_nodes_dict in zip(edge_dict_per, num_nodes_dict_per)]\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;31m# Unbatch node features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/convert.py\u001b[0m in \u001b[0;36mheterograph\u001b[0;34m(data_dict, num_nodes_dict, idtype, device)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;31m# Create the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     metagraph, ntypes, etypes, relations = heterograph_index.create_metagraph_index(\n\u001b[0;32m--> 367\u001b[0;31m         num_nodes_dict.keys(), node_tensor_dict.keys())\n\u001b[0m\u001b[1;32m    368\u001b[0m     \u001b[0mnum_nodes_per_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_nodes_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mntype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mntypes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mrel_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36mcreate_metagraph_index\u001b[0;34m(ntypes, canonical_etypes)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0metypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;31m# metagraph is DGLGraph, currently still using int64 as index dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m     \u001b[0mmetagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_coo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_edges_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_edges_dst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetagraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/graph_index.py\u001b[0m in \u001b[0;36mfrom_coo\u001b[0;34m(num_nodes, src, dst, readonly)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \"\"\"\n\u001b[0;32m-> 1027\u001b[0;31m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/utils/internal.py\u001b[0m in \u001b[0;36mtoindex\u001b[0;34m(data, dtype)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/utils/internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dtype)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/utils/internal.py\u001b[0m in \u001b[0;36m_initialize_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dgl_tensor_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# a dgl ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;31m# a slice type data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/utils/internal.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     88\u001b[0m                                ' but got: %s' % str(data))\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pydata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_tensor_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzerocopy_from_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtonumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prawn/lib/python3.7/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mzerocopy_from_numpy\u001b[0;34m(np_array)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzerocopy_from_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzerocopy_to_dgl_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# svt.Train(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "4a77d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervised_Trainer(SupervisedTrainingWrapper):\n",
    "    def __init__(self,policy_model, **kwargs):\n",
    "        self.policy = policy_model\n",
    "        super().__init__(**kwargs) \n",
    "        \n",
    "        \n",
    "    def TrainModel(self,total_epochs):\n",
    "        \n",
    "        self.Train(total_epochs)\n",
    "        return self.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc6175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
