{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecaeaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    %run MoleculeGenerator2.ipynb\n",
    "#    %run Discrim.ipynb\n",
    " #   %run ChemEnv.ipynb\n",
    "    %run MolUtils.ipynb\n",
    "    #%run Tests.ipynb\n",
    "\n",
    "    \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import time\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7cfae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataLoader():\n",
    "    def __init__(self,path,batch_size, length):\n",
    "        self.path = path\n",
    "        self.length = length\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.indicies = list(range(length))\n",
    "        random.shuffle(self.indicies)\n",
    "        \n",
    "        self.curr_idx = 0\n",
    "        \n",
    "    def __get_exs(self,indices):\n",
    "        graphs, graph_dict = dgl.load_graphs(self.path, indices)\n",
    "        last_action = torch.stack([graph_dict['last_action'][idx] for idx in indices],dim = 0)\n",
    "        last_atom_feat = torch.stack([graph_dict['last_atom_feats'][idx] for idx in indices], dim = 0)\n",
    "        action = torch.stack([graph_dict['actions'][idx] for idx in indices], dim = 0)\n",
    "        graphs = dgl.batch(graphs)\n",
    "        return graphs.to(device), torch.unsqueeze(last_action,dim=1).to(device), last_atom_feat.to(device), action.to(device)\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.curr_idx + self.batch_size > self.length:\n",
    "            self.curr_idx = 0 \n",
    "            random.shuffle(self.indicies)       \n",
    "        batch_indices = self.indicies[self.curr_idx: self.curr_idx+self.batch_size]\n",
    "        self.curr_idx += self.batch_size\n",
    "    \n",
    "        return self.__get_exs(batch_indices)\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e198f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs, graph_dict = dgl.load_graphs('./graph_decomp/full_chunka', [i for i in range(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751cdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = [int(i) for i in (graph_dict['actions'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef58055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(4)\n",
    "# plt.hist(l, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedTrainingWrapper():\n",
    "    def __init__(self, input_dim, batch_size, num_atom_types, writer, data_set_size, path = './graph_decomp/full_chunka'):\n",
    "        #svt = SupervisedTrainingWrapper(54,5,15,None)\n",
    "        self.path = path        \n",
    "        self.policy = BaseLine(input_dim,300,17+1).cuda()\n",
    "        self.optim = Adam(self.policy.parameters(), lr=3e-4)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.chunk_idx = 0\n",
    "        \n",
    "        self.writer = writer\n",
    "        self.n_iter = 0\n",
    "        self.cv_iter = 0\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.data_set_size = data_set_size\n",
    "        self.dataIter = GraphDataLoader(path,batch_size,data_set_size)\n",
    "        print(data_set_size)\n",
    "\n",
    "    def CalcAccuracy(self):\n",
    "        a,b,c,d = next(self.dataIter)\n",
    "        return self.calc_accuracy(a,b,c,d)\n",
    "    \n",
    "    \n",
    "    def calc_accuracy(self,graphs, last_action_nodes, last_atom_feats, actions):\n",
    "        y_logits = self.policy(graphs, last_action_nodes, last_atom_feats)\n",
    "        values, pred_labels = y_logits.max(dim=1)\n",
    "        acc = sum(pred_labels == actions)/actions.size()[0]\n",
    "        return acc\n",
    "    \n",
    "    def calc_accuracy_no_call(self,logits,actions):\n",
    "        values, pred_labels = logits.max(dim=1)\n",
    "        acc = sum(pred_labels == actions)/actions.size()[0]\n",
    "        return acc\n",
    "        \n",
    "        \n",
    "    def Train(self,num_epochs):\n",
    "        steps_per_epoch = self.data_set_size//self.batch_size\n",
    "        \n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            acc = self.CalcAccuracy()\n",
    "            t0 = time()\n",
    "            for step in range(steps_per_epoch):\n",
    "                self._train()\n",
    "            self._train()\n",
    "            t1 = time()\n",
    "            \n",
    "            print(f'Time for epoch {i} is {t1-t0}, random accuracy is {acc}')\n",
    "            \n",
    "            \n",
    "    def _train(self,calc_accuracy = True, update = True):\n",
    "        graphs, last_action_nodes, last_atom_feats, actions = next(self.dataIter)\n",
    "        \n",
    "        pred = self.policy.forward(graphs, last_action_nodes,last_atom_feats, softmax=False)\n",
    "        loss = self.loss_fn(pred,actions.long())\n",
    "        \n",
    "        if calc_accuracy:\n",
    "            acc = self.calc_accuracy_no_call(pred,actions)\n",
    "            self.writer.add_scalar(\"Accuracy\", acc, self.n_iter)\n",
    "        \n",
    "        if update:\n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "        self.writer.add_scalar(\"pre_train_loss\", loss.detach(), self.n_iter)\n",
    "        self.n_iter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # svt = SupervisedTrainingWrapper(54, 2, 17, None, 10000)\n",
    "# # svt.Train(2)\n",
    "# a,b,c,d = (next(svt.dataIter))\n",
    "# print(a)\n",
    "# svt.calc_accuracy(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b935d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gd = GraphDataLoader('./graph_decomp/full_chunka',10,500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run MoleculeGenerator2.ipynb\n",
    "# svt = SupervisedTrainingWrapper(54, 100, 17, None, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd4e07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# svt.Train(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervised_Trainer(SupervisedTrainingWrapper):\n",
    "    def __init__(self,policy_model, **kwargs):\n",
    "        self.policy = policy_model\n",
    "        super().__init__(**kwargs) \n",
    "        \n",
    "        \n",
    "    def TrainModel(self,total_epochs):\n",
    "        \n",
    "        self.Train(total_epochs)\n",
    "        return self.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc6175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
